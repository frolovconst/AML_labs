{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_data(path_to_csv, has_header=True):\n",
    "    \"\"\"\n",
    "    Loads a csv file, the last column is assumed to be the output label\n",
    "    All values are interpreted as strings, empty cells interpreted as empty\n",
    "    strings\n",
    "\n",
    "    returns: X - numpy array of size (n,m) of input features\n",
    "             Y - numpy array of output features\n",
    "    \"\"\"\n",
    "    if has_header:\n",
    "        data = read_csv(path_to_csv, header='infer', dtype=str)\n",
    "    else:\n",
    "        data = read_csv(path_to_csv, header=None, dtype=str)\n",
    "    data.fillna('', inplace=True)\n",
    "    data = data.as_matrix()\n",
    "    X = data[:, :-1]\n",
    "    Y = data[:, -1]\n",
    "    return X, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def my_train_test_split(X, Y, fraction):\n",
    "    \"\"\"\n",
    "    perform the split of the data into training and testing sets\n",
    "    input:\n",
    "        X: numpy array of size (n,m)\n",
    "        Y: numpy array of size (n,)\n",
    "        fraction: number between 0 and 1, specifies the size of the training\n",
    "                data\n",
    "\n",
    "    returns:\n",
    "        X_train\n",
    "        Y_train\n",
    "        X_test\n",
    "        Y_test\n",
    "    \"\"\"\n",
    "    if fraction < 0 or fraction > 1:\n",
    "        raise Exception(\"Fraction for split is not valid\")\n",
    "\n",
    "    # do random sampling for splitting the data\n",
    "    X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=1-fraction)\n",
    "    return X_train, X_test, Y_train, Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,Y = load_data(\"data_1.csv\")\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = my_train_test_split(X, Y, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DTree:\n",
    "    \"\"\"\n",
    "    Simple decision tree classifier for a training data with categorical\n",
    "    features\n",
    "    \"\"\"\n",
    "    _model = None\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self._model = create_branches({'attr_id': -1,\n",
    "                                       'branches': dict(),\n",
    "                                       'decision': None}, X, Y)\n",
    "\n",
    "    def predict(self, X):\n",
    "#         raise NotImplementedError\n",
    "\n",
    "        if X.ndim == 1:\n",
    "            return traverse(self._model, X)\n",
    "        elif X.ndim == 2:\n",
    "            return np.array([traverse(self._model, x) for x in X])\n",
    "        else:\n",
    "            print(\"Dimensions error\")\n",
    "\n",
    "    def prune(self):\n",
    "        \"\"\"\n",
    "        Implement pruning to improve generalization\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def visualise(self):\n",
    "        self.print_node(self._model)\n",
    "        \n",
    "    def print_node(self, node):\n",
    "        print('Node ' )\n",
    "        print( node['attr_id'])\n",
    "        print(node['branches'])\n",
    "        print(node['decision'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_tree = DTree()\n",
    "d_tree.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Ypred = d_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_error(Y_test, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(Y_test, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node \n",
      "0\n",
      "{'Overcast': {'attr_id': -1, 'branches': {}, 'decision': 'Yes'}, 'Rainy': {'attr_id': 3, 'branches': {'Strong': {'attr_id': -1, 'branches': {}, 'decision': 'No'}, 'Weak': {'attr_id': -1, 'branches': {}, 'decision': 'Yes'}}, 'decision': 'Yes'}, 'Sunny': {'attr_id': 2, 'branches': {'High': {'attr_id': -1, 'branches': {}, 'decision': 'No'}, 'Normal': {'attr_id': -1, 'branches': {}, 'decision': 'Yes'}}, 'decision': 'No'}}\n",
      "Yes\n"
     ]
    }
   ],
   "source": [
    "d_tree.visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def elem_to_freq(values):\n",
    "    \"\"\"\n",
    "    input: numpy array\n",
    "    returns: The counts of unique elements, unique elements are not returned\n",
    "    \"\"\"\n",
    "    # hint: check numpy documentation for how to count unique values\n",
    "    classes = np.unique(values)\n",
    "    counts = np.array([values[values==classes[i]].size for i in range(classes.size)])\n",
    "#     raise NotImplementedError\n",
    "    return counts/values.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(elements):\n",
    "    \"\"\"\n",
    "    Calculates entropy of a numpy array of instances\n",
    "    input: numpy array\n",
    "    returns: entropy of the input array based on the frequencies of observed\n",
    "             elements\n",
    "    \"\"\"\n",
    "    # hint: use elem_to_freq(arr)\n",
    "#     raise NotImplementedError\n",
    "    freq = elem_to_freq(elements)\n",
    "    return -(freq.dot(np.log2(freq)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def information_gain(A, X, Y): #S):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        A: the values of an attribute A for the set of training examples\n",
    "        S: the target output class\n",
    "\n",
    "    returns: information gain for classifying using the attribute A\n",
    "    \"\"\"\n",
    "    # hint: use entropy(arr)\\\n",
    "    Ent_S = entropy(Y)\n",
    "    attr_vals = np.unique(X[:,A])\n",
    "    ents = np.array([entropy(Y[X[:,A]==val])*Y[X[:,A]==val].size for val in attr_vals])/Y.size\n",
    "#     raise NotImplementedError\n",
    "    return entropy(Y) - ents.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def choose_best_attribute(X, Y):\n",
    "    \"\"\"\n",
    "    input:\n",
    "        X: numpy array of size (n,m) containing training examples\n",
    "        Y: numpy array of size (n,) containing target class\n",
    "\n",
    "    returns: the index of the attribute that results in maximum information\n",
    "             gain. If maximum information gain is less that eps, returns -1\n",
    "    \"\"\"\n",
    "\n",
    "    eps = 1e-10\n",
    "    max_gain = 0\n",
    "    best_attr = 0\n",
    "    for i in range(X.shape[1]):\n",
    "        c_gain = information_gain(i, X, Y)\n",
    "        if c_gain > max_gain:\n",
    "            max_gain = c_gain\n",
    "            best_attr = i\n",
    "\n",
    "#     raise NotImplementedError\n",
    "    return best_attr if max_gain>eps else -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def most_common_class(Y):\n",
    "    \"\"\"\n",
    "    input: target class values\n",
    "    returns: the value of the most common class\n",
    "    \"\"\"\n",
    "#     raise NotImplementedError\n",
    "    classes = np.unique(Y)\n",
    "    if classes.size==1:\n",
    "        return classes[0]\n",
    "    return classes[0] if Y[Y==classes[0]].size >= Y[Y==classes[1]].size  else classes[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_branches(node, X, Y):\n",
    "    \"\"\"\n",
    "    create branches in a decision tree recursively\n",
    "    input:\n",
    "        node: current node represented by a dictionary of format\n",
    "                {'attr_id': -1,\n",
    "                 'branches': dict(),\n",
    "                 'decision': None},\n",
    "              where attr_id: specifies the current attribute index for branching\n",
    "                            -1 mean the node is leaf node\n",
    "                    braches: is a dictionary of format {attr_val:node}\n",
    "                    decision: contains either the best guess based on\n",
    "                            most common class or an actual class label if the\n",
    "                            current node is the leaf\n",
    "        X: training examples\n",
    "        Y: target class\n",
    "\n",
    "    returns: input node with fields updated\n",
    "    \"\"\"\n",
    "    # choose best attribute to branch\n",
    "    attr_id = choose_best_attribute(X,Y)\n",
    "    node['attr_id'] = attr_id\n",
    "    # record the most common class\n",
    "    node['decision'] = most_common_class(Y)\n",
    "#     print('best a=', attr_id)\n",
    "    if attr_id != -1:\n",
    "        # find the set of unique values for the current attribute\n",
    "        attr_vals = np.unique(X[:,attr_id])\n",
    "\n",
    "        for a_val in attr_vals:\n",
    "            # compute the boolean array for slicing the data for the next\n",
    "            # branching iteration\n",
    "            # hint: use logical operation on numpy array\n",
    "            # for more information about slicing refer to numpy documentation\n",
    "            sel = X[:,attr_id]==a_val\n",
    "            # perform slicing\n",
    "            X_branch = X[sel, :]\n",
    "            Y_branch = Y[sel]\n",
    "            node_template = {'attr_id': -1,\n",
    "                             'branches': dict(),\n",
    "                             'decision': None}\n",
    "            # perform recursive call\n",
    "            node['branches'][a_val] = create_branches(node_template, X_branch, Y_branch)\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d_tree = DTree()\n",
    "d_tree.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = d_tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_error(Y_test, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(Y_test, Ypred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "d_tree.visualise()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def traverse(model,sample):\n",
    "    \"\"\"\n",
    "    recursively traverse decision tree\n",
    "    input:\n",
    "        model: trained decision tree\n",
    "        sample: input sample to classify\n",
    "\n",
    "    returns: class label\n",
    "    \"\"\"\n",
    "    if model['attr_id'] == -1:\n",
    "        decision = model['decision']\n",
    "    else:\n",
    "        attr_val = sample[ model['attr_id'] ]\n",
    "        if attr_val not in model['branches']:\n",
    "            decision = model['decision']\n",
    "        else:\n",
    "            decision = traverse(model['branches'][attr_val], sample)\n",
    "    return decision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def measure_error(Y_true, Y_pred):\n",
    "    \"\"\"\n",
    "    returns an error measure of your choice\n",
    "    \"\"\"\n",
    "    return Y_true[Y_true==Y_pred].size/Y_true.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall(Y_true, Y_pred):\n",
    "    \"\"\"\n",
    "    returns recall value\n",
    "    \"\"\"\n",
    "    \n",
    "    Y_t = np.array((Y_true=='yes') | (Y_true=='Yes') | (Y_true=='1')) + 0\n",
    "    Y_p = np.array((Y_pred=='yes') | (Y_pred=='Yes') | (Y_pred=='1')) + 0\n",
    "    return recall_score(Y_t, Y_p)\n",
    "\n",
    "\n",
    "# 1.  test your implementation on data_1.csv\n",
    "#     refer to lecture slides to verify the correctness\n",
    "# 2.  test your implementation on mushrooms_modified.csv\n",
    "# 3.  test your implementation on titanic_modified.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['No', 'No', 'Yes', 'Yes', 'Yes', 'No', 'Yes', 'No', 'Yes', 'Yes',\n",
       "       'Yes', 'Yes', 'Yes', 'No'], dtype=object)"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 1 1 1 0 1 0 1 1 1 1 1 0]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recall(Y,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly classified: 100.00%\n",
      "Recall 1.0000\n"
     ]
    }
   ],
   "source": [
    "Y_pred = d_tree.predict(X_test)\n",
    "print(\"Correctly classified: %.2f%%\" % (measure_error(Y_test,Y_pred) * 100))\n",
    "print(\"Recall %.4f\" % recall(Y_test, Y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xm,Ym = load_data(\"mushrooms_modified.csv\")\n",
    "Xm_train, Xm_test, Ym_train, Ym_test = my_train_test_split(Xm, Ym, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt,Yt = load_data(\"titanic_modified.csv\")\n",
    "Xt_train, Xt_test, Yt_train, Yt_test = my_train_test_split(Xt, Yt, .8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
