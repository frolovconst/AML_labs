{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score for original features:  0.6914485090073325\n",
      "Score for transformed features:  0.7129525372325883\n",
      "Gain:  0.021504028225255878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.6/site-packages/scipy/stats/stats.py:245: RuntimeWarning: The input array could not be properly checked for nan values. nan values will be ignored.\n",
      "  \"values. nan values will be ignored.\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv, get_dummies, concat\n",
    "from numpy import mean, dtype\n",
    "from scipy.stats import mode\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# In this assignment you are going to work with Pandas\n",
    "# what is assessed is your ability to work with documentation\n",
    "# overall you need to write 5 lines of code\n",
    "# Go through the following code line by line and complete\n",
    "# the functions fill_na and embed_categories\n",
    "\n",
    "#        Taks Description\n",
    "# In current task you are going to do data pre-processing for KNN algorithm.\n",
    "# KNN with euclidean distance metric is designed to work only with numerical features\n",
    "# You are going to test KNN on modified Titanic dataset. You can get familiar with\n",
    "# dataset header in the file titanic_modified.csv\n",
    "\n",
    "# You are going to complete two types of pre-processing:\n",
    "# 1. Eliminating Null (N/A) values\n",
    "# 2. Mapping categorical features to binary indicator features\n",
    "\n",
    "def load_data(path_to_csv, has_header=True):\n",
    "    \"\"\"\n",
    "    Loads a csv file, the last column is assumed to be the output label\n",
    "    All values are interpreted as strings, empty cells interpreted as empty\n",
    "    strings\n",
    "\n",
    "    returns: X - pandas DataFrame of shape (n,m) of input features\n",
    "             Y - numpy array of output features of shape (n,)\n",
    "    \"\"\"\n",
    "    if has_header:\n",
    "        data = read_csv(path_to_csv, header='infer')\n",
    "    else:\n",
    "        data = read_csv(path_to_csv, header=None)\n",
    "    X = data.loc[:, data.columns[:-1] ]\n",
    "    Y = data.loc[:, data.columns[-1]  ]\n",
    "    return X, Y.as_matrix()\n",
    "\n",
    "\n",
    "X, Y = load_data(\"titanic_modified.csv\")\n",
    "\n",
    "def fill_na(X):\n",
    "    \"\"\"\n",
    "    Iterates over columns of DataFrame X, any N/A values replaced by the most\n",
    "    frequent element in the column\n",
    "    :param X: DataFrame with input features\n",
    "    :return: copy of the DataFrame with N/A replaced by the most frequent elements\n",
    "    \"\"\"\n",
    "    # Just to be safe, create a copy of current DataFrame\n",
    "    X = X.copy()\n",
    "    for i in range(X.shape[1]):\n",
    "        col_name = X.columns[i]         # current column name\n",
    "        is_null = X[col_name].isnull()  # check for N/A values\n",
    "        if is_null.any():\n",
    "            # Find the most frequent element value in the current column\n",
    "            # Hint: use the function mode from scipy.stats\n",
    "            # Hint: input slice for mode function can be obtained as\n",
    "            #       X.loc[~is_null, col_name]\n",
    "            # Hint: be careful with N/A values\n",
    "            #None  # <- Replace this line\n",
    "            mfv, f = mode(X.loc[~is_null,col_name])\n",
    "#             print(mfv)\n",
    "#             print(where(is_null))\n",
    "            # Replace N/A entries with most_common value\n",
    "            # Hint: slice DataFrame with X.loc[???]\n",
    "            # Hint: make use of is_null when slicing\n",
    "#             None  # <- Replace this line\n",
    "            X.loc[is_null, col_name] = mfv\n",
    "    return X\n",
    "\n",
    "def embed_categories(X):\n",
    "    \"\"\"\n",
    "    Replaces columns with categorical features by binary feature indicator columns\n",
    "    :param X: DataFrame with input features\n",
    "    :return: DataFrame with binary feature indicators\n",
    "    \"\"\"\n",
    "    X = X.copy()\n",
    "    n_features = X.shape[1]\n",
    "    c_feature = 0\n",
    "\n",
    "    while c_feature < n_features:\n",
    "\n",
    "        col_name = X.columns[c_feature]     # Get current column name\n",
    "        current_type = X.dtypes[c_feature]  # Get current column type\n",
    "\n",
    "        if current_type == dtype(object):\n",
    "            # Your goal is to transform the values of categorical features\n",
    "            # into binary feature indicators.\n",
    "            # This procedure requires to transform a data sample of the format\n",
    "            # Specie | Height | Weight\n",
    "            #    Cat |     30 |      3\n",
    "            #    Dog |     50 |     10\n",
    "            #\n",
    "            # Into the format\n",
    "            # Height | Weight | Cat | Dog\n",
    "            #     30 |      3 |   1 |   0\n",
    "            #     50 |     10 |   0 |   1\n",
    "            #\n",
    "            # Luckily Pandas can do the hardest part for you with the function get_dummies\n",
    "            # Hint: use get_dummies from Pandas. The input should be the current column\n",
    "            crnt_features = get_dummies(X[col_name])\n",
    "            # Drop the column you have just transformed\n",
    "            # Since you replace features with binary indicators,\n",
    "            # old features is no use for you any more\n",
    "            # Hint: use drop from Pandas.DataFrame to remove current column\n",
    "            X.drop(columns=[col_name], inplace=True)\n",
    "            # Concatenate the rest of the DataFrame with new columns\n",
    "            # Hint: use function concat from Pandas\n",
    "            # Hint: Pay attention to the argument axis\n",
    "            X = concat((X, crnt_features), axis=1)\n",
    "\n",
    "            n_features -= 1\n",
    "        else:\n",
    "            c_feature += 1\n",
    "    # Cast DataFrame to matrix\n",
    "    return X.as_matrix()\n",
    "\n",
    "def k_fold_validation(X, Y):\n",
    "    kf = KFold(n_splits=50)\n",
    "    fold_score = []\n",
    "    for train_index, test_index in kf.split(X):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "\n",
    "        knn = KNeighborsClassifier()\n",
    "        knn.fit(X_train, y_train)\n",
    "        y_pred = knn.predict(X_test)\n",
    "        fold_score.append(f1_score(y_test, y_pred))\n",
    "    return mean(fold_score)\n",
    "\n",
    "X = fill_na(X)\n",
    "X = embed_categories(X)\n",
    "\n",
    "# Test the performance with one hot categorical feature embeddings\n",
    "s1 = k_fold_validation(X, Y)\n",
    "print(\"Score for original features: \", s1)\n",
    "\n",
    "# After checking the performance of this classification procedure\n",
    "# apply a dimensionality reduction technique (PCA). It several\n",
    "# purposes:\n",
    "# 1. Implicit data normalization (PCA pre-processing)\n",
    "# 2. Feature orthogonalization\n",
    "# 3. Dimensionality reduction\n",
    "\n",
    "# Apply Principal Component Analysis\n",
    "num_components = X.shape[1]-2      # reduce features dimension by 2\n",
    "pca = PCA(n_components=num_components)\n",
    "X_tran = pca.fit_transform(X)\n",
    "\n",
    "# Test the performance with transformed features\n",
    "s2 = k_fold_validation(X_tran, Y)\n",
    "print(\"Score for transformed features: \", s2)\n",
    "print(\"Gain: \", s2 - s1)           # You should observe gain around 1-3%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
