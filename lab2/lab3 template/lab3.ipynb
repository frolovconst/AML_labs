{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Version Space:\n",
      "S:  [array(['Japan', '?', '?', '?', 'Economy'], dtype=object)]\n",
      "G:  [array(['Japan', '?', '?', '?', 'Economy'], dtype=object)]\n"
     ]
    }
   ],
   "source": [
    "from pandas import read_csv\n",
    "import numpy as np\n",
    "\n",
    "def load_data(path_to_csv, has_header=True):\n",
    "    if has_header:\n",
    "        data = read_csv(path_to_csv, header='infer')\n",
    "    else:\n",
    "        data = read_csv(path_to_csv, header=None)\n",
    "    data = data.as_matrix()\n",
    "    X = data[:, 0:-1]\n",
    "    Y = data[:, -1]\n",
    "    return X, Y\n",
    "\n",
    "class CandidateElimination:\n",
    "\n",
    "    # candidate elimination algorithm\n",
    "    def fit(self, training_data, labels):\n",
    "        S = self.initialize_to_first_positive(training_data, labels)\n",
    "        G = self.initialize_to_most_general(training_data)\n",
    "        training_examples = len(training_data)\n",
    "        for i in range(training_examples):\n",
    "            if labels[i] == \"yes\":\n",
    "                G = [g for g in G if self.is_consistent(training_data[i], g, True)]\n",
    "                not_consistent = [s for s in S if not self.is_consistent(training_data[i], s, True)]\n",
    "                S = [s for s in S if self.is_consistent(training_data[i], s, True)]\n",
    "                for n in not_consistent:\n",
    "                    self.add_min_generalization(n, training_data[i], G, S)\n",
    "                S = [s for s in S if not self.is_more_general_than_any(s, S)]\n",
    "            else:\n",
    "                S = [s for s in S if self.is_consistent(training_data[i], s, False)]\n",
    "                not_consistent = [g for g in G if not self.is_consistent(training_data[i], g, False)]\n",
    "                G = [g for g in G if self.is_consistent(training_data[i], g, False)]\n",
    "                for n in not_consistent:\n",
    "                    self.add_min_specialization(n, training_data[i], S, G, training_data)\n",
    "                G = [g for g in G if not self.is_less_general_than_any(g, G)]\n",
    "        print(\"Final Version Space:\")\n",
    "        print(\"S: \", S)\n",
    "        print(\"G: \", G)\n",
    "\n",
    "    def initialize_to_first_positive(self, training_data, labels):\n",
    "        \"\"\"\"\n",
    "        Returns list with one hypothesis which is equal to the first positive example\n",
    "        \"\"\"\n",
    "        for i in range(len(labels)):\n",
    "            if labels[i] == 'yes':\n",
    "                init_set = [training_data[i, :]]\n",
    "                return init_set\n",
    "\n",
    "    def initialize_to_most_general(self, training_data):\n",
    "        \"\"\"\"\n",
    "        Returns list with one most general hypothesis - ['?', '?', '?', '?'...]\n",
    "        \"\"\"\n",
    "        hypothesis = []\n",
    "        for i in range(training_data.shape[1]):\n",
    "            hypothesis.append(\"?\")\n",
    "        return [np.array(hypothesis, dtype=object)]\n",
    "\n",
    "    def is_consistent(self, training_example, hypothesis, is_positive):\n",
    "        \"\"\"\"\n",
    "        Returns True if the hypothesis classifies the training_example as:\n",
    "            - positive if it's positive\n",
    "            - negative if it's negative\n",
    "        \"\"\"\n",
    "        # %%% TODO START YOUR CODE HERE %%%\n",
    "\n",
    "        n = training_example.size\n",
    "        if is_positive == True:\n",
    "            for i in range(n):\n",
    "                if hypothesis[i]!='?' and hypothesis[i]!=training_example[i]:\n",
    "                    return False\n",
    "            return True\n",
    "        else:\n",
    "            for i in range(n):\n",
    "                if hypothesis[i]!=training_example[i] and hypothesis[i]!='?' :\n",
    "                    return True\n",
    "            return False\n",
    "        # %%% END YOUR CODE HERE %%%\n",
    "    \n",
    "\n",
    "    def add_min_generalization(self, hypothesis, training_example, G, S):\n",
    "        \"\"\"\n",
    "        Makes the hypothesis consistent with training_example\n",
    "        Adds it to S if some member of G is more general\n",
    "        \"\"\"\n",
    "        # %%% TODO START YOUR CODE HERE %%%\n",
    "        new_hypothesis = hypothesis.copy()\n",
    "        for idx,el in enumerate(new_hypothesis):\n",
    "            if new_hypothesis[idx] != training_example[idx]:\n",
    "                new_hypothesis[idx] = \"?\"\n",
    "\n",
    "        if not self.is_more_general_than_any(new_hypothesis,G):\n",
    "            S.append(new_hypothesis)\n",
    "            \n",
    "    def add_min_specialization(self, hypothesis, negative_example, S, G, training_data):\n",
    "        \"\"\"\n",
    "        Generates all possible minimal specializations by replacing '?' by all possible values except for value in negative example\n",
    "        Adds each such specialization to G if some member of S is more specific than the specialization\n",
    "        \"\"\"\n",
    "        # %%% TODO START YOUR CODE HERE %%%\n",
    "        n = hypothesis.size\n",
    "        unique_els = [np.unique(training_data[:,idx]) for idx in range(n)]\n",
    "        new_S = list()\n",
    "        for i in range(n):\n",
    "            if hypothesis[i] == '?':\n",
    "                for v in unique_els[i][unique_els[i]!=negative_example[i]]:\n",
    "                    new_h = hypothesis.copy()\n",
    "                    new_h[i] = v\n",
    "                    new_S += (new_h,)\n",
    "        add_to_G = [h for h in new_S if self.is_more_general_than_any(h, S)]\n",
    "        G += add_to_G\n",
    "\n",
    "    def is_more_general_than_any(self, hypothesis, set):\n",
    "        \"\"\"\n",
    "        Checks if the hypothesis is more general than any hypothesis in the set\n",
    "        \"\"\"\n",
    "        for h in set:\n",
    "            if self.is_more_general(hypothesis, h):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "    def is_less_general_than_any(self, hypothesis, set):\n",
    "        \"\"\"\n",
    "        Checks if the hypothesis is less general than any hypothesis in the set\n",
    "        \"\"\"\n",
    "        for h in set:\n",
    "            if self.is_more_general(h, hypothesis):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def is_more_general(self, hypothesis1, hypothesis2):\n",
    "        \"\"\"\n",
    "        Returns True if hypothesis1 is more general than hypothesis2\n",
    "        \"\"\"\n",
    "        # %%% TODO START YOUR CODE HERE %%%\n",
    "        more_gen = False\n",
    "        for idx, el in enumerate(hypothesis1):\n",
    "            if hypothesis1[idx] != hypothesis2[idx]:\n",
    "                if hypothesis1[idx] == '?':\n",
    "                    more_gen = True\n",
    "                    continue\n",
    "                else:\n",
    "                    return False\n",
    "        return more_gen\n",
    "\n",
    "        # %%% END YOUR CODE HERE %%%\n",
    "\n",
    "\n",
    "    def is_equal(self, hypothesis1, hypothesis2):\n",
    "        \"\"\"\n",
    "        Returns True if hypotheses are equal\n",
    "        \"\"\"\n",
    "        for i in range(len(hypothesis1)):\n",
    "            if hypothesis1[i] != hypothesis2[i]:\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "X, Y = load_data(\"cars.csv\")\n",
    "\n",
    "CE = CandidateElimination()\n",
    "\n",
    "CE.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i= 0\n",
      "j= ??????\n"
     ]
    }
   ],
   "source": [
    "for i,j in enumerate(['?' '?' '?' '?' '?' '?']):\n",
    "    print('i=',i)\n",
    "    print('j=',j)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['yes', 'no', 'yes', 'no', 'yes'], dtype=object)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Japan', 'Honda', 'Blue', 1980, 'Economy'], dtype=object)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
